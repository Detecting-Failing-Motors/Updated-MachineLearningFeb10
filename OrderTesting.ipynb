{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Native Libraries\n",
    "#import pandas as pd\n",
    "#import numpy as np \n",
    "#import copy\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Needed Created Functions\n",
    "\n",
    "#Need 2 Functions to extract all the data from csv files\n",
    "from ExtractDataFunctions import ExtractAccelerometerData\n",
    "from ExtractDataFunctions import ExtractAcousticData\n",
    "\n",
    "#Need 3 Functions to Organize all the all the data\n",
    "from OrganizationFunctions import Inputs2CondensedForm\n",
    "from OrganizationFunctions import System2CondensedForm\n",
    "from OrganizationFunctions import AllData2WorkingForm\n",
    "\n",
    "#Need 1 Function to Organize Files into TestDataFrame\n",
    "from FeatureFunctions import getTESTDataFrame\n",
    "\n",
    "#Need 2 Functions for Graphing\n",
    "from FeatureFunctions import getGraphs\n",
    "from FeatureFunctions import getQuickPlot\n",
    "\n",
    "#Need # Functions to perform Machine Learning\n",
    "from MachineLearningFunctions import getTESTMatrix\n",
    "from MachineLearningFunctions import GenerateTrainingFile\n",
    "from MachineLearningFunctions import GetSplitTrainingData\n",
    "from MachineLearningFunctions import GetTrainingData\n",
    "from MachineLearningFunctions import TrainModel\n",
    "from MachineLearningFunctions import PredictModel\n",
    "from MachineLearningFunctions import PredictProbModel\n",
    "from MachineLearningFunctions import GetReducedFeaturesFromDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receive GUI Inputs\n",
    "\n",
    "#General\n",
    "Name_ID = \"1\"\n",
    "Application = \"2\"\n",
    "ModelNumber = \"3\"\n",
    "SavingAlias = \"4\"\n",
    "#AccelerometerDataFilename = 'AccelerometerActualData.csv' #filename #Origninal / Additionally File\n",
    "AccelerometerDataFilename = 'AccelerometerActualDataEdited.csv' #filename #main file\n",
    "#AcousticDataFilename = 'DataOutputMic.csv' #Original File #Wave File Name\n",
    "AcousticDataFilename = 'DataOutputMic2Col.csv' #Wave File Name\n",
    "MLDataFilename = \"MLSynthesizedData.csv\"\n",
    "\n",
    "#Motor Characteristics #Need to get with Brendan\n",
    "Horsepower = \"6\"\n",
    "RatedVoltage = \"7\"\n",
    "ACorDC = \"DC\"\n",
    "NumberOfPolePairs = \"9\"\n",
    "NumberofShafts = \"10\"\n",
    "\n",
    "#Bearing Information\n",
    "ShaftSpeed = 300 #Also Used for Motor Characteristics\n",
    "NumberOfRollingElements = 3\n",
    "DiameterOfRollingElements = 3\n",
    "PitchDiameter = .2\n",
    "ContactAngle = .2\n",
    "\n",
    "#Processing Information \n",
    "AccelerometerSamplingFrequency = 14000 #must be an non-zero int or float\n",
    "AcousticSamplingFrequency = 20000 #must be an non-zero int or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Microcontroller Information\n",
    "#Receive Required Information\n",
    "A2DResolution = 16\n",
    "VoltageMax = 5\n",
    "VoltageMin = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#System/Sensor Known Constants\n",
    "AccelerationMax = 50 \n",
    "AccelerationMin = -50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert User Inputs into a condensed form\n",
    "OnlyUserInput = Inputs2CondensedForm(Name_ID, Application, ModelNumber, SavingAlias,\\\n",
    "                                     AccelerometerDataFilename, AcousticDataFilename, \\\n",
    "                                     MLDataFilename, Horsepower, RatedVoltage, ACorDC, \\\n",
    "                                     NumberOfPolePairs, NumberofShafts, \\\n",
    "                                     ShaftSpeed, NumberOfRollingElements, \\\n",
    "                                     DiameterOfRollingElements,PitchDiameter, ContactAngle, \\\n",
    "                                     AccelerometerSamplingFrequency, AcousticSamplingFrequency)\n",
    "\n",
    "SystemInputs = System2CondensedForm(A2DResolution,VoltageMax,VoltageMin,AccelerationMax,AccelerationMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire Accelerometer Actual Data\n",
    "time, amp, Voltage, Acceleration = ExtractAccelerometerData(OnlyUserInput,SystemInputs)\n",
    "\n",
    "#Acquire Acoustic Actual Data\n",
    "Channel1Time,Channel1Value,Channe21Time,Channe2Value = ExtractAcousticData(OnlyUserInput,SystemInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put All Data into Working Form\n",
    "trial = 2 #Select the instance of the data\n",
    "AllData = AllData2WorkingForm(OnlyUserInput,SystemInputs,time[trial], \\\n",
    "                              amp[trial], Voltage[trial], Acceleration[trial],\\\n",
    "                             Channel1Time,Channel1Value,Channe21Time,Channe2Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for Machine Learning\n",
    "TestDF = getTESTDataFrame(AllData)\n",
    "TestMatrix = getTESTMatrix(TestDF)\n",
    "ShortDF = GetReducedFeaturesFromDataFrame(TestDF)\n",
    "ShortTestMatrix = getTESTMatrix(ShortDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GENERATE TRAINING DATA FILE\n",
    "\"\"\"\n",
    "#GenerateTrainingFile(AllData,\"MLSynthesizedData.csv\")\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GET TRAINING DATA\n",
    "\"\"\"\n",
    "\n",
    "#Split training datasets for validation\n",
    "#Used in scoring\n",
    "X_train, X_test, Y_train, Y_test = GetSplitTrainingData(AllData)\n",
    "\n",
    "#For trainging over entire file\n",
    "#Used in final classifier\n",
    "#Not used in scoring\n",
    "Xall_train, Yall_train, dataset = GetTrainingData(AllData)\n",
    "\n",
    "#Entire Set with Reduced Features\n",
    "ShortDataset = GetReducedFeaturesFromDataFrame(dataset)\n",
    "ShortXallTrain = ShortDataset.values[:,0:(ShortDataset.shape[1]-1)]\n",
    "ShortYallTrain = Yall_train\n",
    "\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 2. 0. 1. 1. 0. 0. 1. 0. 1. 1.]\n",
      "['Suspect', 'Normal', 'Normal', 'Suspect', 'Suspect', 'Failure', 'Suspect', 'Normal', 'Normal', 'Suspect', 'Suspect', 'Normal', 'Suspect', 'Normal', 'Normal']\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.43      0.60      0.50         5\n",
      "        1.0       0.14      0.50      0.22         2\n",
      "        2.0       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.16      0.27      0.20        15\n",
      "\n",
      "\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL VALIDATION\n",
    "\n",
    "Demonstrate Selected Model's results using\n",
    "classification report\n",
    "\n",
    "Test on the split model\n",
    "\"\"\"\n",
    "\n",
    "#Train\n",
    "Classifier = TrainModel(X_train, Y_train)\n",
    "\n",
    "\n",
    "#Predict\n",
    "Y_pred,Y_pred_string = PredictModel(Classifier,X_test)\n",
    "\n",
    "print(Y_pred)\n",
    "print(Y_pred_string)\n",
    "\n",
    "#Output Results\n",
    "#\n",
    "print('\\n')\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print('\\nfinished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SAVING FINAL TRAINED MODELS\n",
    "\n",
    "Train on Final Model using all of the training data\n",
    "\"\"\"\n",
    "#Save Full Model\n",
    "FinalClassifier = TrainModel(Xall_train, Yall_train)\n",
    "SaveFilename = 'FullModel.sav' #saving name\n",
    "pickle.dump(FinalClassifier, open(SaveFilename, 'wb')) # Save Model Using Pickle\n",
    "\n",
    "#Save Short Model\n",
    "ShortClassifier = TrainModel(ShortXallTrain,ShortYallTrain)\n",
    "ShortSaveFilename = 'ShortModel.sav'\n",
    "pickle.dump(ShortClassifier, open(ShortSaveFilename, 'wb'))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model:\n",
      "\n",
      "['Failure']\n",
      "[[18.00449408 13.01237149 68.98313443]]\n",
      "\n",
      "\n",
      "Short Model:\n",
      "\n",
      "['Failure']\n",
      "[[17.43682425 16.50400412 66.05917163]]\n",
      "\n",
      "\n",
      "Loaded Model:\n",
      "\n",
      "['Failure']\n",
      "[[18.00449408 13.01237149 68.98313443]]\n",
      "\n",
      "\n",
      "Loaded Short Model:\n",
      "\n",
      "['Failure']\n",
      "[[17.43682425 16.50400412 66.05917163]]\n",
      "\n",
      "finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'END OF MODEL CHARACTERIZING'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PREDICTION RESULTS on TestMatrix/ShortTestMatrix\n",
    "\"\"\"\n",
    "\n",
    "#Currently Trained Model\n",
    "prediction,prediction_string = PredictModel(FinalClassifier,TestMatrix)\n",
    "prediction_proba = PredictProbModel(FinalClassifier,TestMatrix)\n",
    "#Output Results\n",
    "print('Full Model:\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "\n",
    "#Current Short Classifier\n",
    "prediction,prediction_string = PredictModel(ShortClassifier,ShortTestMatrix)\n",
    "prediction_proba = PredictProbModel(ShortClassifier,ShortTestMatrix)\n",
    "#Output Results\n",
    "print('\\n')\n",
    "print('Short Model:\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "\n",
    "#Current Saved Loaded Model\n",
    "SaveFilename = 'FullModel.sav' #saving name\n",
    "LoadedClassifier = pickle.load(open(SaveFilename, 'rb')) #Load the saved model using Pickle\n",
    "#Predict\n",
    "prediction,prediction_string = PredictModel(LoadedClassifier,TestMatrix)\n",
    "prediction_proba = PredictProbModel(LoadedClassifier,TestMatrix)\n",
    "#Output Results\n",
    "print('\\n')\n",
    "print('Loaded Model:\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "\n",
    "#Current Saved ShortModel\n",
    "ShortSaveFilename = 'ShortModel.sav' #saving name\n",
    "LoadedClassifier = pickle.load(open(ShortSaveFilename, 'rb')) #Load the saved model using Pickle\n",
    "prediction,prediction_string = PredictModel(LoadedClassifier,ShortTestMatrix)\n",
    "prediction_proba = PredictProbModel(LoadedClassifier,ShortTestMatrix)\n",
    "#Output Results\n",
    "print('\\n')\n",
    "print('Loaded Short Model:\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "\n",
    "print('\\nfinished')\n",
    "\n",
    "\"\"\"END OF MODEL CHARACTERIZING\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
